---
title: "Sesión 9"
---

# Regresión lineal (II)

## Paquetes

Vamos a utilizad "pacman" para cargar los paquetes que utilizaremos en esta sesión

```{r, warning=FALSE}
#install.packages("sjPlot", dependencies=T) # solito porque da problmas
library(sjPlot)

if (!require("pacman")) install.packages("pacman") # instala pacman si se requiere
pacman::p_load(tidyverse, # sobretodo para dplyr
              haven, #importación
              janitor, #tablas
              sjlabelled, # etiquetas
              DescTools, # Paquete para estimaciones y pruebas
              infer, # tidy way 
              broom,  # Una escobita para limpiar (pero es para arreglar)
              estimatr, car, stargazer, ggpubr, 
              performance,
              effects,
              jtools, lm.beta, robustbase, sandwich,
              officer,flextable,huxtable, ggstance, kableExtra) # Para la regresión


```

## Datos

E importamos la base e incluimos los cambios anteriores

```{r}
etiqueta_sex<-c("Hombre", "Mujer")

concentrado2022 <- haven::read_dta("datos/concentrado2022.dta")  %>% 
  mutate(sexo_jefe=as.numeric(sexo_jefe)) %>% ## para quitar el "string"
  sjlabelled::set_labels(sexo_jefe, labels=etiqueta_sex) %>% 
  mutate(clase_hog=as.numeric(clase_hog)) %>% ## para quitar el "string"
  sjlabelled::set_labels(clase_hog, labels=c("unipersonal",
                                             "nuclear", 
                                             "ampliado",
                                             "compuesto",
                                             "corresidente")) %>% 
  mutate(educa_jefe=as.numeric(educa_jefe)) %>% 
  set_labels(educa_jefe,
             labels=c("Sin instrucción", 
                      "Preescolar",
                      "Primaria incompleta",
                      "Primaria completa",
                      "Secundaria incompleta",
                      "Secundaria completa",
                      "Preparatoria incompleta",
                      "Preparatoria completa",
                      "Profesional incompleta",
                      "Profesional completa",
                      "Posgrado")) %>% 
    mutate(ent=stringr::str_sub(folioviv, start=1, end=2 )) %>% 
    mutate(ing_per=ing_cor/tot_integ) %>% 
    mutate(recibe_rem=remesas>0)
  
```

## Sub-setting y modelos clase anterior

Vamos a hacer una sub-base de nuestras posibles variables explicativas. Esto es importante porque sólo podemos comparar modelos con la misma cantidad de observaciones.

```{r}
mydata<- concentrado2022 %>% 
  select(folioviv, foliohog, tam_loc, ing_per, sexo_jefe, 
         educa_jefe, edad_jefe, tot_integ, clase_hog, ent) %>%  
  mutate_at(vars(educa_jefe, sexo_jefe, clase_hog), ~ as_label(.x)) %>% 
  mutate(log_ing_per=log(ing_per)) %>% 
  filter(!is.infinite(log_ing_per))


tail(mydata)

```

Modelos:

```{r}

modelo <-stats::lm(log_ing_per ~ edad_jefe, 
                   data=mydata, 
            na.action=na.exclude)

modelo1 <-stats::lm(log_ing_per ~ edad_jefe + sexo_jefe, 
                   data=mydata, 
            na.action=na.exclude)

modelo2<-stats::lm(log_ing_per ~ edad_jefe + sexo_jefe + tot_integ , 
            data=mydata, 
            na.action=na.exclude)

modelo3<-stats::lm(log_ing_per ~ edad_jefe + sexo_jefe + tot_integ + educa_jefe, 
            data=mydata, 
            na.action=na.exclude)

```

## Estandarizando que es gerundio

Comparar los resultados de los coeficientes es difícil, porque el efecto está medido en unidades de alguna escala. Por lo que no sería tan comparable el efecto que tenemos de nuestro índice sumativo (proporción de lugares con inseguridad declarada) con respecto a la edad (que se mide en años). Por lo que a veces es mejor usar las medida estandarizadas (es decir, muestra puntajes $Z$).

Podemos hacerlo transformando nuestras variables de origen e introducirlas al modelo. O bien, podemos usar un paquete que lo hace directamente. Los coeficientes calculados se les conoce como "beta"

Simplemente aplicamos el comando a nuestros modelos ya calculados

```{r}
lm.beta(modelo2)
```

Hoy la comparación será mucho más clara y podemos ver qué variable tiene mayor efecto en nuestra dependiente.

```{r}
modelo_beta<-lm.beta(modelo3)
modelo_beta
```

Para graficarlos, podemos usar de nuevo el comando `sjPlot::plot_model()`, con una opción

```{r}
sjPlot::plot_model(modelo3, type="std")

sjPlot::plot_model(modelo3, 
                   type="std", 
                   show.values = T,
                   value.offset = 0.2)

```

¿Qué podemos concluir de estos resultados?

## Post-estimación

### Las predicciones

Por este comando transformamos nuestras variables estiquetadas.

```{r}

summary(modelo2)
```

Unos de los usos más comunes de los modelos estadísticos es la predicción

```{r}
sjPlot::plot_model(modelo2, type="pred", terms = "edad_jefe")
```

También podemos incluir la predecciones para los distintos valores de las variables

```{r}
sjPlot::plot_model(modelo2, type="pred", terms = c("edad_jefe", "sexo_jefe")) + theme_blank()
```

El orden de los términos importa:

```{r}
plot_model(modelo2, type="pred", terms = c("sexo_jefe","edad_jefe")) + theme_blank()
```

### Efectos marginales

Con los efectos marginales, por otro lado medimos el efecto promedio, dejando el resto de variables constantes.

```{r}
sjPlot::plot_model(modelo2, type="eff", terms ="edad_jefe")
sjPlot::plot_model(modelo2, type="eff", terms = "sexo_jefe")

```

¿Es el mismo gráfico que con "pred"? Veamos la ayuda

¿Y si queremos ver esta informaicón graficada?

```{r}
eff<-plot_model(modelo2, type="eff", terms = "edad_jefe")
eff$data

```

```{r}
eff<-plot_model(modelo2, type="pred", terms = "edad_jefe")
eff$data
```

## Extensiones del modelo de regresión

### Introducción a las interacciones

Muchas veces las variables explicativas van a tener relación entre sí. Por ejemplo ¿Las horas tendrá que ver con el sexo y afectan no sólo en intercepto si no también la pendiente? Para ello podemos introducir una interacción

```{r}
modelo_int1<-lm(log_ing_per ~ edad_jefe * sexo_jefe , 
                data = mydata,
                na.action=na.exclude)

summary(modelo_int1)
```

Esta interacción lo que asume es que las pendientes pueden moverse (aunque en este caso específico no lo hacen tanto porque no nos salió significativa)

```{r}
plot_model(modelo_int1, 
           colors = "Accent", #RColorBrewer
           type="int", 
           terms = c("sex", "edad_jefe"), 
           title = "Ingreso corriente según edad  y sexo del jefe o jefa")

```

## Efectos no lineales

### Explicitando el logaritmo

```{r}

modelo_log<-lm(log(ing_per) ~ log(edad_jefe) + sexo_jefe,
               data=mydata, 
               na.action = na.exclude)

summary(modelo_log)

```

```{r}
plot_model(modelo_log, type="pred", terms ="edad_jefe")

```

### Efecto cuadrático

```{r}
modelo_quadr<-lm(log_ing_per ~ edad_jefe + I(edad_jefe^2) + sexo_jefe, 
                 data=mydata, 
                 na.action=na.exclude)

summary(modelo_quadr)

```

Quizás con un gráfico de lo predicho tenemos más claro lo que hace ese término

```{r}
plot_model(modelo_quadr, type="pred", terms = c("edad_jefe"))

```

En efecto, lo que nos da el signo del cuadrático puede hablarnos del comportamiento cóncavo hacia arriba o hacia abajo. La edad muchas veces tiene este comportamiento en algunos fenómenos.

## No cumplo los supuestos

### Heterocedasticidad

El problema de la heterocedasticidad es que los errores estándar de subestiman, por lo que si estos están en el cociente de nuestro estadístico de prueba t, esto implicaría que nuestras pruebas podrían estar arrojando valores significativos cuando no lo son.

Una forma muy sencilla es pedir los errores robustos, esto se puede desarrollar con el paquete `{estimatr}`

<https://declaredesign.org/r/estimatr/articles/getting-started.html>

```{r}
modelo2rob1 <- estimatr::lm_robust(log_ing_per ~ edad_jefe + 
                           sexo_jefe + 
                           tot_integ, 
                         data = mydata)
summary(modelo2rob1)

broom::tidy(modelo2rob1)
broom::glance(modelo2rob1)

```

### Errores en clúster

Cuando tenemos individuos que pertenecen a una misma unidad, podemos crear errores anidados en clúster: \[Esto se puede tardar un poco\]

```{r}
modelo2rob2<- estimatr::lm_robust(log_ing_per ~ edad_jefe +
                         sexo_jefe +
                         tot_integ,
                        data = mydata, 
                        clusters = ent)

summary(modelo2rob2)
```

### Paquete `{jtools}`

Jacob Long is back!

<https://cran.r-project.org/web/packages/jtools/vignettes/summ.html>

```{r}
jtools::summ(modelo2, robust = "HC1")
```

También `summ()` funciona para estandarizar:

```{r}
jtools::summ(modelo2, scale = TRUE)

```

## Regresión robusta

```{r}

modelo2rob3<-robustbase::lmrob(log_ing_per ~ edad_jefe +
                                 sexo_jefe +
                                 tot_integ,
                               data = mydata, 
                               na.action = na.exclude)

summary(modelo2rob3)

```

**No es lo mismo la regresión robusta que los errores robustos.**

**La regresión robusta es más robusta a los outliers. No confundir**.

La regresión robusta, es esto, *robusta a los valores atípicos*, porque pesa el valor de las observaciones de tal manera que los outliers tenga menor influencia.

## Comparando modelos

Usaremos `{stargazer}` para revisar nuestros modelos. Los modelos que usamos con `{estimatr}` al tener más información (como los intervalos de confianza), no podemos introducirlos directamente.

```{r mytextable2}

stargazer::stargazer(modelo2, 
                     modelo2rob3, 
                     type = 'text', 
                     header=FALSE)

```

Así que ni modo. `{stargazer}` nos acompañó mucho mucho tiempo.

Pues `{jtools}` nos salvó la vida:

```{r}
jtools:::export_summs(modelo2, 
                      modelo2rob1, 
                      modelo2rob2,
                      modelo2rob3)

```

Estas tablas también están muy lindas y pueden exportarse a otros formatos:

```{r}
# jtools::export_summs(modelo2, modelo2rob1, modelo2rob2, modelo2rob3, 
#                      to.file = "PDF",
#                      file.name = "test.pdf")
```

## Extra:

Revisando `{jtools}`:

```{r}
jtools::plot_summs(modelo2,
          scale=T,
          plot.distributions = TRUE, 
          inner_ci_level = .9)
```

## Un poquito de reflexión

Se pueden usar métodos no paramétricos, como la regresión mediana (checar el paquete `{quantreg}`. O como ya vimos podemos transformar la variable a logaritmo, seleccionar casos.

Es recomendable mejor utilizar otro tipo de modelos más robustos a la presencia de outliers (i.e. regresión robusta) y menos dependientes de una distribución normal (i.e. regresión mediana).
